{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from boto3 import client as boto_client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 262144\n",
    "to_rad = np.pi / 180\n",
    "to_deg = 180 / np.pi\n",
    "\n",
    "campaign = 'Olympex'\n",
    "collection = \"AirborneRadar\"\n",
    "dataset = \"gpmValidationOlympexcrs\"\n",
    "variables = [\"ref\"]\n",
    "renderers = [\"point_cloud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_vector(roll, pitch, head):\n",
    "    x = np.sin(roll) * np.cos(head) + np.cos(roll) * np.sin(pitch) * np.sin(head)\n",
    "    y = -np.sin(roll) * np.sin(head) + np.cos(roll) * np.sin(pitch) * np.cos(head)\n",
    "    z = -np.cos(roll) * np.cos(pitch)\n",
    "    return (x, y, z)\n",
    "\n",
    "def CRSaccess(fname, s3bucket=False, Verb=False):\n",
    "    \"\"\"\n",
    "    Access the CRS file\n",
    "    Return CRS filename with path (absolute path) for \"local\" access\n",
    "    Return CRS data as object for \"cloud access\"\n",
    "    Either way, the return value can be open by Xarray as netcdf file object\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\%% Accessing data from Cloud. This may take a little time...\\n\")\n",
    "    s3 = boto_client('s3')\n",
    "    fileobj = s3.get_object(Bucket=s3bucket, Key=fname)\n",
    "    fileCRS = fileobj['Body'].read()\n",
    "\n",
    "    return fileCRS\n",
    "\n",
    "def add24hr(hr):\n",
    "    \"\"\"Correction of time in CRS for going over the next day in UTC\"\"\"\n",
    "    b = np.where(hr < hr[0])\n",
    "    hr[b] = hr[b] + 24\n",
    "    return hr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(folder, file, s3bucket):\n",
    "    \"\"\"\n",
    "    Converts Level 1B crs data from s3 to zarr file and then stores it in the provided folder\n",
    "    Args:\n",
    "        folder (string): name to hold the raw files.\n",
    "        file (string): the s3 url to the raw file.\n",
    "    \"\"\"\n",
    "    store = zarr.DirectoryStore(folder)\n",
    "    root = zarr.group(store=store)\n",
    "    \n",
    "    # !!! Define dataset for necessary generic data.\n",
    "    z_chunk_id = root.create_dataset('chunk_id', shape=(0, 2), chunks=None, dtype=np.int64)\n",
    "    z_location = root.create_dataset('location', shape=(0, 3), chunks=(chunk, None), dtype=np.float32)\n",
    "    z_time = root.create_dataset('time', shape=(0), chunks=(chunk), dtype=np.int32)\n",
    "\n",
    "    # !!! Define group for value\n",
    "    z_vars = root.create_group('value')\n",
    "    # !!! Define dataset for actual value that will get plotted.\n",
    "    z_ref = z_vars.create_dataset('ref', shape=(0), chunks=(chunk), dtype=np.float32)\n",
    "\n",
    "    # !!! define a empty array. FOR WHAT??? DONOT HAVE ANY IDEA.\n",
    "    n_time = np.array([], dtype=np.int64)\n",
    "\n",
    "    # !!! Extract the date information from the file name. The date is the date when the data was collected from the instrument.\n",
    "    date = file.split(\"_\")[2]\n",
    "    base_time = np.datetime64('{}-{}-{}'.format(date[:4], date[4:6], date[6:]))\n",
    "\n",
    "    print(\"Accessing file from S3 \", file)\n",
    "\n",
    "    # read from s3 url (file) in s3 bucket.\n",
    "    fileObj = CRSaccess(file, s3bucket=s3bucket)\n",
    "\n",
    "    # open dataset.\n",
    "    with xr.open_dataset(fileObj, decode_cf=False) as ds:\n",
    "        #### time correction start\n",
    "        # !!! (logic????) added for time correction for time (hour) over 24h UTC\n",
    "        hr = add24hr(ds['timed'].values)\n",
    "\n",
    "        # !!! addition of date to all time rows i.e. {date + time} for all rows.\n",
    "        # Note: \"delta\" is an intermediatery before final time correction.\n",
    "        delta = (hr * 3600).astype('timedelta64[s]') + base_time\n",
    "        # now delta will have this sort of value: ['2015-11-10T17:28:16' '2015-11-10T17:28:16' '2015-11-10T17:28:17' ...\n",
    "        # '2015-11-10T18:01:05' '2015-11-10T18:01:05' '2015-11-10T18:01:05']\n",
    "        \n",
    "        #### time correction end\n",
    "        \n",
    "        # Data COLS EXTRACT \n",
    "        ref = ds[\"zku\"].values #CRS radar reflectivity\n",
    "        rad_range = ds[\"range\"].values\n",
    "\n",
    "        lat = ds['lat'].values\n",
    "        lon = ds['lon'].values\n",
    "        alt = ds['altitude'].values # altitude of aircraft in meters\n",
    "        roll = ds[\"roll\"].values\n",
    "        pitch = ds[\"pitch\"].values\n",
    "        head = ds[\"head\"].values\n",
    "    num_col = ref.shape[0] # number of cols, say 7903\n",
    "    num_row = ref.shape[1] # number of rows, say 757\n",
    "\n",
    "    ##### EXTRACTED COLS\n",
    "    # timed, lat, lon, alt, roll, pitch, head,\n",
    "    # ref(zku), rad_range(range)\n",
    "    #####\n",
    "\n",
    "    ##### data frame formation\n",
    "\n",
    "    ## repeat each value element consecutively row times. WHY???\n",
    "    delta = np.repeat(delta, num_row)\n",
    "    lon = np.repeat(lon, num_row)\n",
    "    lat = np.repeat(lat, num_row)\n",
    "    alt = np.repeat(alt, num_row)\n",
    "    roll = np.repeat(roll * to_rad, num_row)\n",
    "    pitch = np.repeat(pitch * to_rad, num_row)\n",
    "    head = np.repeat(head * to_rad, num_row)\n",
    "\n",
    "    ## repeat each value element consecutively col times\n",
    "    rad_range = np.tile(rad_range, num_col)\n",
    "    ## !!! REPEAT OTHER DATA WRT REF (THE MAIN THING TO PLOT), THEN FLATTEN THE REF.\n",
    "    ref = ref.flatten()\n",
    "\n",
    "    # time correction final\n",
    "    # !!! before subtraction, first the datetime is set to precision of seconds, then it is converted into int64\n",
    "    time = (delta - np.datetime64('1970-01-01')).astype('timedelta64[s]').astype(np.int64)\n",
    "\n",
    "    # !!! needed for {lon lat alt} correction with respect to rad range and roll, pitch, head value. Why is it necessary ???\n",
    "    x, y, z = down_vector(roll, pitch, head)\n",
    "    x = np.multiply(x, np.divide(rad_range, 111000 * np.cos(lat * to_rad)))\n",
    "    y = np.multiply(y, np.divide(rad_range, 111000))\n",
    "    z = np.multiply(z, rad_range)\n",
    "    lon = np.add(-x, lon)\n",
    "    lat = np.add(-y, lat)\n",
    "    alt = np.add(z, alt)\n",
    "\n",
    "    # !!! sort data by time\n",
    "    sort_idx = np.argsort(time) # returns indices that will sort the array\n",
    "    lon = lon[sort_idx]\n",
    "    lat = lat[sort_idx]\n",
    "    alt = alt[sort_idx]\n",
    "    ref = ref[sort_idx]\n",
    "    time = time[sort_idx]\n",
    "\n",
    "    # !!! Remove nan and infinite using mask\n",
    "    # check if ref is finite and alt value is greater than 1, element wise\n",
    "    # index mask to filter infinite ref value and alt value which is greater than 1\n",
    "    mask = np.logical_and(np.isfinite(ref), alt > 0)\n",
    "    lon = lon[mask]\n",
    "    lat = lat[mask]\n",
    "    alt = alt[mask]\n",
    "    ref = ref[mask]\n",
    "    time = time[mask]\n",
    "\n",
    "    ### !!! ZARR DATASETS POPULATION\n",
    "    # Now populate (append) the empty rows with modified data.\n",
    "    z_location.append(np.stack([lon, lat, alt], axis=-1)) #!!! first convert position info as [[lon, lat, alt], ....], before appending\n",
    "    z_ref.append(ref)\n",
    "    n_time = np.append(n_time, time) # Basically converts into array with single dim; very similar to spread operator.\n",
    "\n",
    "    idx = np.arange(0, n_time.size, chunk) # arange: Return evenly spaced values within a given interval. (start, stop, steps)\n",
    "    chunks = np.zeros(shape=(idx.size, 2), dtype=np.int64) # create zero array of given shape. here (indexsize x 2)\n",
    "    chunks[:, 0] = idx\n",
    "    chunks[:, 1] = n_time[idx]\n",
    "    z_chunk_id.append(chunks)\n",
    "    \n",
    "    epoch = np.min(n_time)\n",
    "    n_time = (n_time - epoch).astype(np.int32) ## why done this??? i.e. adding date to time information first, then later subtract datetime. \n",
    "    z_time.append(n_time)\n",
    "\n",
    "    # save it.\n",
    "    root.attrs.put({\n",
    "        \"campaign\": campaign,\n",
    "        \"collection\": collection,\n",
    "        \"dataset\": dataset,\n",
    "        \"variables\": variables,\n",
    "        \"renderers\": renderers,\n",
    "        \"epoch\": int(epoch)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing file from S3  Olympex/instrument-raw-data/crs/olympex_CRS_20151110_172815-20151110_175946_2_v01a.nc\n",
      "\\%% Accessing data from Cloud. This may take a little time...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder = f\"/tmp/crs_olympex/zarr/11111111\"\n",
    "bucket_name=\"ghrc-fcx-field-campaigns-szg\"\n",
    "s3_raw_file_key= \"Olympex/instrument-raw-data/crs/olympex_CRS_20151110_172815-20151110_175946_2_v01a.nc\"\n",
    "\n",
    "ingest(folder, s3_raw_file_key, bucket_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the written file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tree' object has no attribute '_ipython_display_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/itsc-fcx-n/lib/python3.10/site-packages/IPython/core/formatters.py:921\u001b[0m, in \u001b[0;36mIPythonDisplayFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    919\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 921\u001b[0m     method()\n\u001b[1;32m    922\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/itsc-fcx-n/lib/python3.10/site-packages/zarr/util.py:538\u001b[0m, in \u001b[0;36mTreeViewer._ipython_display_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ipython_display_\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    537\u001b[0m     tree \u001b[39m=\u001b[39m tree_widget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroup, expand\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand, level\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevel)\n\u001b[0;32m--> 538\u001b[0m     tree\u001b[39m.\u001b[39;49m_ipython_display_()\n\u001b[1;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m tree\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tree' object has no attribute '_ipython_display_'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "/\n",
       " ├── chunk_id (3, 2) int64\n",
       " ├── location (646799, 3) float32\n",
       " ├── time (646799,) int32\n",
       " └── value\n",
       "     └── ref (646799,) float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = zarr.DirectoryStore(folder)\n",
    "root = zarr.group(store=store)\n",
    "root.tree()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=\"20151009\"\n",
    "dt = np.datetime64('{}-{}-{}'.format(date[:4], date[4:6], date[6:]))\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = np.datetime64('2022-01-01').astype('timedelta64[s]')\n",
    "print(dt1)\n",
    "dt2 = dt1.astype(np.int64)\n",
    "print(dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = ['2015-11-10T17:28:16', '2015-11-10T17:28:16', '2015-11-10T17:28:17', '2015-11-10T18:01:05', '2015-11-10T18:01:05', '2015-11-10T18:01:05']\n",
    "np.repeat(ttt, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.array([1, 2, 3])\n",
    "lat = np.array([4, 5, 6])\n",
    "np.stack(([lon, lat]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmw = ([np.datetime64(x) for x in ttt]  - np.datetime64('1970-01-01')).astype('timedelta64[s]').astype(np.int64)\n",
    "tmw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(tmw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itsc-fcx-n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "499a5fb3fec32ad917a576b01fa5ecfdef941a73b5948d57fad4fa0146a62e96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
